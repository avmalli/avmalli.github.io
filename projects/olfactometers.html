<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Olfactometer Software &amp; System Refinement | Amritha Mallikarjun</title>
  <link rel="stylesheet" href="../styles.css" />
</head>

<body>
  <div class="wrapper">
    <header>
      <div class="name">Amritha Mallikarjun, Ph.D.</div>
      <nav>
        <a href="../index.html">Home</a>
        <a href="../publications.html">Publications</a>
        <a href="../projects.html">Projects</a>
        <a href="../cv.html">CV</a>
        <a href="../contact.html">Contact</a>
      </nav>
    </header>

    <main>
      <h1>Olfactometer software &amp; system refinement</h1>
      <p class="subhead">
        I led a rapid, iterative redesign of research-grade control software into a tool that non-expert trainers could run reliably
        in high-tempo studies—without crashes, missing data, or fragile “only works if you click the right thing” workflows.
      </p>

      <div class="section">
        <h2>Context</h2>
        <p>
          We use portable, automated olfactometers to run controlled canine olfaction experiments. The physical devices were built
          by collaborators at Texas Tech, and we received an initial codebase intended for expert research users. The system itself is
          powerful—computer-controlled odor presentation, sensor-based response capture, and automated trial structure—but the first
          version of the software assumed perfect inputs and would fail hard when real users did normal things: skipping a field,
          selecting an unexpected option, or running an edge-case trial sequence.
        </p>

        <div class="project-image">
      <img src="/olfactometers.jpg" alt="Working dog using automated olfactometer system at the Penn Vet Working Dog Center. Inset shows internal electronics and tubing of the device.">
      <p class="image-caption">
          Portable automated olfactometer system used for controlled odor presentation and response capture in canine detection studies.
      </p>
</div>

      </div>

      <div class="section">
        <h2>Problem</h2>
        <ul class="publist">
          <li class="pub">
            <p class="citation">
              <strong>Fragility:</strong> The program crashed on common input errors (e.g., starting a lineup with no odor selected; selecting a dog name
              not present in the backend list).
            </p>
          </li>
          <li class="pub">
            <p class="citation">
              <strong>Usability gap:</strong> Trainers needed clear workflow prompts in the UI and a way to adjust settings mid-run
              without restarting the whole program to improve usablility and flexibility.
            </p>
          </li>
          <li class="pub">
            <p class="citation">
              <strong>Errors lead to delays:</strong> Each program crash delayed session timing, and the difficulty using the program caused missing data and introduced inconsistencies across experimenters.
            </p>
          </li>
        </ul>
      </div>

      <div class="section">
        <h2>My role</h2>
        <p>
     I redesigned portions of both the backend logic and the user interface to improve reliability, reduce failure points, and support non-expert users (dog trainers and researchers without a programming background).
        </p>
      </div>

      <div class="section">
        <h2>What I built</h2>

        <p class="note">Selected examples (mix of reliability work, UX improvements, and data pipeline engineering):</p>

        <ul class="publist">
          <li class="pub">
            <p class="citation">
              <strong>Defensive input handling:</strong> Added validation and guardrails so common mistakes produced helpful feedback instead of a crash
              (e.g., blocking “start trial” when required fields are missing; handling unexpected dog/odor values gracefully).
            </p>
          </li>

          <li class="pub">
            <p class="citation">
              <strong>User-driven feature development:</strong> Added additional features to ease workflow for me, the experimenters, and the trainers. 
              For example, I designed an in-trial timer so trainers could structure the trials in the most conducive way for the dogs
              at a glance.
            </p>
          </li>

          <li class="pub">
            <p class="citation">
              <strong>Flexible settings:</strong> Implemented a “change settings” pathway so trainers could correct configuration errors or adjust parameters
              between trials without closing and reopening the program. Implemented a "skip trial" button to easily move past unwanted trials without waiting a minute for it to time out.
            </p>
          </li>

          <li class="pub">
            <p class="citation">
              <strong>Streamlined data capture and upload:</strong> Designed (and with a computer science intern, implemented) a workflow that automatically packages
              and uploads session data to Airtable, reducing manual file handling and improving consistency across experimenters.
            </p>
          </li>

          <li class="pub">
            <p class="citation">
              <strong>Operational robustness:</strong> Focused on easy-to-implement features that reduce real-world failure: clearer prompts, safer defaults,
              and predictable recovery behavior when something goes off-script.
            </p>
          </li>
        </ul>
      </div>

<div class="section">
  <h2>Why this matters</h2>

  <p>
    The original software was built by and for specific users who already understood the system’s assumptions. In practice, our researchers and trainers needed to run structured experiments quickly and consistently, without worrying about whether a missing field or unexpected input would crash a session or corrupt a dataset.
  </p>

  <p>
    I rewrote validation logic, clarified trial configuration workflows, and added safeguards against common edge cases. I also standardized output formatting to make downstream statistical analysis more reliable. This make workflow easier for program users and ensured that the data we collected was complete and accurate. 
  </p>

  <p>
    For me, this project captures an important part of applied research and human-computer interaction. Building easy-to-use, flexible tools supports rigorous experimental work.
  </p>
</div>


      <div class="section">
        <h2>Skills reflected</h2>
        <div class="links">
          <span class="note">Applied software engineering</span>
          <span class="note">Human-centered design</span>
          <span class="note">Reliability under messy inputs</span>
          <span class="note">Experiment ops</span>
          <span class="note">Data pipelines (Airtable)</span>
        </div>
      </div>

      <div class="section">
        <h2>Media</h2>
        <p class="note">
          Optional: add a screenshot of the UI, a photo of the portable olfactometer setup, or a simple diagram of the session flow.
          If you want, I can format an image grid that matches the site style once you drop in filenames.
        </p>
      </div>

      <p class="note">
        Back to <a href="../projects.html">Projects</a>.
      </p>
    </main>

    <footer>
      &copy; <span id="y"></span> Amritha Mallikarjun
    </footer>
  </div>

  <script>
    document.getElementById("y").textContent = new Date().getFullYear();
  </script>
</body>
</html>

